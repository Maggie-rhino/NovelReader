{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880d3460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a63259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971ffbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54283285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a404d8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_start =\"https://onehu.xyz\"\n",
    "start_idx =2\n",
    "end_idx =234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac946cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(url):\n",
    "    resp = requests.get(url)\n",
    "    soup = BeautifulSoup(resp.content,'html.parser')\n",
    "    novel_lists = soup.find_all(class_ = \"row\")\n",
    "    \n",
    "    res =[]\n",
    "    for item in novel_lists:\n",
    "        # Find elements\n",
    "        header_text = item.find(class_=\"index-header\").get_text(strip=True)\n",
    "        header_href = item.find(class_=\"index-header\").find('a')['href']\n",
    "        excerpt_text = item.find(class_=\"index-excerpt\").get_text(strip=True)\n",
    "        date_text = item.find(\"time\").get_text(strip=True)\n",
    "        category_text = item.find(class_=\"category-chain-item\").get_text(strip=True)\n",
    "        tag_text = item.find_all(\"div\", class_=\"post-meta\")[-1].get_text(strip=True)\n",
    "        res.append([header_text,header_href,excerpt_text,date_text,category_text,tag_text])\n",
    "    cols =['title','url','abstract','date','category','tag']\n",
    "    df =pd.DataFrame(res,columns=cols)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "#     df.to_csv(save_path,index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf59b196",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "articles_df = get_info(url_start)\n",
    "for i in tqdm(range(2,307)):\n",
    "    url =f\"https://onehu.xyz/page/{i}/#board\"\n",
    "    page_df = get_info(url)\n",
    "    articles_df =pd.concat([articles_df,page_df])\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d22020",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df.to_csv(\"./data/articles_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb4f5b1",
   "metadata": {},
   "source": [
    "### get the article\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e939b4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df =pd.read_csv('./data/articles_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c79ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569dbe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_items =[]\n",
    "error_items =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a096c4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df['txt_path'] =None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd93c6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "for idx,row in tqdm(articles_df.iterrows()):\n",
    "    n +=1\n",
    "    full_url = f\"https://onehu.xyz{row.url}\"\n",
    "    resp = requests.get(full_url)\n",
    "    page_soup = BeautifulSoup(resp.content,'html.parser')\n",
    "    content = page_soup.find(class_ =\"markdown-body\")\n",
    "    if content is None:\n",
    "        continue\n",
    "    folder =f\"./data/{row.url[1:11]}\"\n",
    "    if os.path.exists(folder):\n",
    "        pass\n",
    "    else:\n",
    "        os.system(f\" mkdir -p {folder}\")\n",
    "        print(\"folder does not exist, create a new folder \",folder)\n",
    "    txt_path =f'{folder}/{n-1}.txt'\n",
    "    articles_df.loc[n-1,'txt_path']=txt_path\n",
    "#     print(\"save the content\")\n",
    "    with open (txt_path,'w') as f:\n",
    "        f.write(content.get_text())\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51ba5b2",
   "metadata": {},
   "source": [
    "### data clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aa1a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df =articles_df[[\"title\",'url','abstract','date','category','tag','txt_path']]\n",
    "articles_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf141b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = articles_df[articles_df.txt_path.isna()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8234ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_clean.drop_duplicates(subset='abstract',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876ab3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['txt_path'] = df_clean['txt_path'].apply(lambda x : x.replace('./data/','').replace('.txt',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e184f68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean =df_clean[['title', 'url', 'abstract', 'date', 'category',\n",
    "       'tag', 'txt_path']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0625aac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['tag'] =df_clean['tag'].apply(lambda x : x.replace(\"#\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7e09b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('./data/articles_df_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7c782c",
   "metadata": {},
   "source": [
    "### category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666d9d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_list =[]\n",
    "\n",
    "category_set = df_clean['category'].unique().tolist()\n",
    "\n",
    "\n",
    "for c in category_set:\n",
    "    sub_df = df_clean[df_clean['category']==c]\n",
    "    cnt = len(sub_df)\n",
    "    lists = sub_df[['title','txt_path']].to_dict(orient='records')[:11]\n",
    "    category_list.append({\"category\":c,\"count\":cnt,\"lists\":lists})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46ba41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_data = sorted(category_list, key=lambda x: x['count'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e5afe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad13ff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/category_lists.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(sorted_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9b00bd",
   "metadata": {},
   "source": [
    "### search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3768c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4715f1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"zh_core_web_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9bd1016",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean =pd.read_csv('./data/articles_df_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60512835",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['search_keywords'] = df_clean.apply(lambda x : '|'.join([i for i in x[['title','category','abstract']]]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "697ab5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input text\n",
    "n=0\n",
    "def filter_NER(text):\n",
    "    \n",
    "    # Process the text\n",
    "    doc = nlp(text)\n",
    "    # Tokenization\n",
    "    tokens = [token.text for token in doc]\n",
    "    # Display Part-of-Speech (POS) and Lemmatization (Optional)\n",
    "    return doc.ents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33262fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                              | 0/5819 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/sd/zkcs20_92lj8p18hjphygv8c0000gn/T/jieba.cache\n",
      "Loading model cost 0.297 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5819/5819 [00:04<00:00, 1452.47it/s]\n"
     ]
    }
   ],
   "source": [
    "search_NER=[]\n",
    "\n",
    "for i in  tqdm(df_clean['search_keywords'].tolist()):\n",
    "    ents = jieba.lcut(i)\n",
    "    search_NER.append(ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49c9d1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['search_NER'] = search_NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "70736eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['search_NER']= df_clean['search_NER'].apply(lambda x : [i for i in x if len(i)>1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e90fa54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[['title', 'url', 'abstract', 'date', 'category', 'tag',\n",
    "       'txt_path', 'search_NER']].to_csv('./data/articles_df_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "61d21d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "string =\"我是个假千金\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366f1033",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
